电话社交网络的研究
 土盘测试  http://106.15.228.74:7474/browser/      


社交网络构建设想：
  总的来说：电话网络的构建有两种，依据目前的运营商数据，origin数据中，有用户的通话详单，report中有用户的通话记录统计信息，
	  第一种网络设想是参考浙江大学杨洋教授的思路，构建一个纯用户的同构社交网络，那用户之间的关系是怎么定义呢，就是说只要两个用户有过通话
	  就在这两个用户之间建立连接，这个关系属性主要包括通话时长，通话次数，通话时间，依据origin数据，拿到全量的origin数据，解析数据到网络中，最后
	  会将网络中孤立的节点剔除掉，或是直接构建有联系的用户，这样的一个网络中直接考虑了借贷人的直接联系，这样的网络会凸显出联系紧密的群体或是团伙，
	  我觉得最大的挑战是数据融合和清洗，工程量是比较大的。总之这样的网络主要去挖掘用户之间的联系。
	  关于通话网络的研究主要参考 https://dl.ccf.org.cn/audioVideo/detail.html?id=4161731848882176 
	   杨洋教授的研究，相关的论文地址  https://zhuanlan.zhihu.com/p/34544862?edition=yidianzixun&utm_source=yidianzixun&yidian_docid=0IYYbJDZ
	  
	  第二种就是我们下面介绍的，通过用户的通话记录统计信息建立网络，在这个网络中只要和借贷人存在联系的电话，在满足一定的条件下都可能进入网络中，
	  report数据的特点是他统计了每一个和借贷人有过交互的电话，以及他们的通话主叫被叫次数，这样的数据我们拿来构建的是一个庞大的电话社交网，
	  主要的挑战一方面来自于源数据量就比较大，另一方面网络的数据负荷是一个比较大的考验，还有一个比较大的难点是，数据清洗，因为这一一个通话网络
	  的构建主要作用可能是中介挖掘，团伙监控等，根据目前的网络建设的情况来看，一些社会服务电话会干扰我们的挖掘工作，比如快递，餐饮，司机，等等号码，
	  这些中间人是作为很多用户的通话记录中的，但是这些通话本身不存在欺诈风险和中介风险，所有电话标签在这个网络中尤其重要，这对于鉴别中介团伙等等问题
	  是很重要的，就算清洗工作做得比较完善，我们可以很快挖掘出一些联系紧密的社区，很常见的情况就是很多借贷人都与同一个电话存在紧密联系，那这样的中间电话
	  是有风险考虑的，但是最终还是要人工去查，去确定这样的电话最终的属性。这样的通话网络可能更趋向于中介挖掘，团伙监控等
	  
	  虽然这个网络主要基于通话数据，但是基于运营商数据，我们还可以引入其他的数据来构建起用户之间的联系，
	  考虑加入用户地址信息，做地址融合，考虑加入紧急联系人 ，设备号，以及平台账号等，这是后期工作，估量工作量是非常大的
  
  第一版： 是按照第二种方式考虑单纯的构建电话网络或者，是通话之间建立关系，中间不算人这一层 人作为电话的附属，
       因为真正的欺诈电话或是中介中心很有可能不会参与进件，只负责中介。在这个网络中只存在电话或者说，将用户附属在电话节点周围。
	   到目前看来效果不好，因为没有对数据标签进行清洗，导致网络节点冗余，一个借贷人的通话节点平均200，这样的网络数据量太大，而且社会服务电话干扰巨大。
	  
	 
  第二版： 网络的结构变化不大，主要工作集中在数据清洗 
          目前是按照进件的时间顺序，去解析运营商报告，这次还是建立通话关系，人作为本人电话的附属节点，
		这次需要将订单的通过情况，贷后情况带入网络中去，做标记，第一版数据融合过滤太过于差，最后导致网络比较乱，虽然确实可以看到很多借贷人联系了
		同一个人，但是目前看来很有可能是这个中间人是快递，司机，一些社会服务人员普遍是这些中间节点，这些人是需要过滤的，还有就是一些弱联系的电话也进入了网络
		比如主动call借贷人一次的电话

		1 数据整理  data_fuse/call_data_analysis.py
			1 数据获取：以用户id为中心，获取其电话和通话记录，并进行数据融合，目前原则上取当前用户的最新征信数据的通话记录作为原始通话数据
			2 数据融合：只拿该用户最近三个月的通话数据，提取申请人电话号码，提取申请人三个月通话记录号码,但是考虑到没有通话日期，所以获取全量通话数据
			具体问题：由于很多用户的通话记录都是空的，所以还是通过运营商报告解析通话数据
					  运营商报告来自于5个渠道，这些渠道的报告格式都不是完全一样的，通过对于报告的解析分析，得到如下特征
					  moxie：魔蝎：按通话次数降序，没有通话日期，有呼出呼入次数时长，有电话标记
					  jxl：聚信立：通话次数无序，没有通话日期，有呼出呼入次数时长，有电话标记
					  lhp：量化派：按通话次数降序，有通话日期，有呼出呼入次数时长，无电话标记
					  dhb：贷后邦：通话次数无序，没有通话日期，有呼出呼入次数时长，有电话标记
					  rong360      按通话次数降序，有通话日期，有呼出呼入次数时长，有电话标记
			3 数据下载	
				将通话数据按照 电话号码：通话次数|主叫|被叫|电话标记    的形式写入文件	
				1 通过解析得到各个渠道的数据比例是： {'mix': 0, 'jxl': 403, 'lhp': 0, 'dhb': 48, 'rong': 0}
				2 电话标记高频关键词：移动 银行，酒店 送餐 餐饮 菜 客栈 餐厅 汽车 维修 有限公司 宾馆 旅行社 美容 地产 物流 快递 信托
				
			4 数据统计
				1001-1003订单量 117316 对于一个借贷人被叫次数远高于主叫次数，
				这其中 所有通话电话数量 43807446  主叫0次 29661950 虚拟和上网号码量 524531 电话有标签数量： 6335367   
					   命中关键词数量 3954135 借贷人主叫0次命中数量 3157105，也就是说借贷人主动呼叫这些社会服务电话情况比较少
				从统计结果来看，所有通话中 有四分之三的通话都是借贷人被呼叫而且借贷人没有再次联系这些电话，这些电话成为中介或是团伙的概率比较小的
				
			5 数据清洗
				1 从以上分析来看，主叫0次的电话号码占去很大一部分，还有命中一些社会服务的电话号码无论联系多么频繁，看起来都和欺诈无关
				2 还有很多号码虽然号码一致但是标签不一致，比如一些社会号码12533之类的，还有就是同一个电环号码既是借款人电话号码又是通话记录中的一个
				  导致流入网络之后无法融合在一起，这种数据需要做融合
				 这些数据是需要过滤
				
				
			6 网络结构
				节点；phone：id(电话号码),label(电话标签)  person: id(身份证号), is_black,overdue..
				关系：call: times(通话次数),c_out(主叫),c_in(被叫)
				
				tips: 在使用gephi时遇到的坑： 节点属性的命名，第一版的时候，没有命名问题是因为当时没有中文在网络中，这次引入电话标签后，
				APOC的导入数据到gephi的函数报了错，无奈之下只能，先将neo4j数据转存graphml文件，然后导入gephi，但是这里就出现了命名问题，
				call apoc.export.graphml.query('match path = (pe:person)-[r]->(p:phone)-[rel]->(t:phone) return pe,r,p,rel,t','C:/Users/Administrator/Desktop/exportAll4.graphml',{useTypes:true})
				如果我把id设置为节点的属性，文件导入gephi时id这个属性居然没有引入，我只好把id转换成pid之类的，这次数据可以流进gephi，但是并没有赋值到
				gephi的Lable标签上，最后只好把电话号码身份证设置为label字段，电话标签设置为mark
				
			最后决定
			第一步：导入数据时统一标签都是no，
			第二步：是更新标签值，将借款人更新为loaner，将有标签的电话更新到对应的标签
			第三步：将逾期情况更新到网络中，包括借款人节点和借款人电话节点
  
  第三版：将异构网络转化为同构网络
  后期比较高大上的图算法可能是要基于同构网络展开，在这样同构网络中只有借贷用户，
  同构到异构转换目前我还没有解决方案，我的想法是讲电话网络复制到一个新的库，然后将电话节点融合掉只剩下用户节点，
  还有一种比较宏大的方案就是，基于用户通过用户的各种资源来构建用户之间的关系，比如，首先通话通话记录，无论是origin也好还好report的数据也好，
  再次要去查询用户地址相似性，用户设备关联，用户账号的关联
  
  最后的拍板方案是：全量用户运营商数据融合之后写入mongodb，包括用户基础信息，地址，通话记录，通讯录，紧急联系人，
  网络的设计方案是，只要借贷人之间存在联系即建立连接，包括 1，拥有相同电话，2互相通话，3互为联系人，4，互为紧急联系人 
  


		
			
  

2 导入neo4j
      创建索引：CREATE INDEX ON :phone(id)  明显提高查询和写入速度
	  
	  主要用于对于一些即为中间号码又为申请人号码的节点做融合
	  MERGE (p:phone { id: '18981062617' })
		ON CREATE SET p.is_loaner=-1
		ON MATCH SET p.is_loaner=1


3 图谱挖掘

  1查看所有二度关联的中间电话并计数，主要为了统计一些官方电话
  match path = (p:phone)-[rel]->(t)<-[r]-(other) return t.id,count(t.id) order by count(t.id) desc
  
  查看通话次数统计情况
  match (p:phone)-[rel]-(o:phone) return rel.times,count(rel.times) order by count(rel.times) desc
  
  1. 中介挖掘: 主要挖掘中介团伙，通过申请人的共同联系人网络分析
	  
	   查看所有二度关联的中间电话
		  match (p:phone)-[r]->(o)<-[rel]-(ph:phone) return p,o,ph
		  
		  导出关联数据到gephi
		  match path = (p:phone)-[rel]->(t:phone)<-[r]-(other)
					WITH path LIMIT 100000
					with collect(path) as paths
					call apoc.gephi.add(null,'test', paths) yield nodes, relationships, time
					return nodes, relationships, time
				
		  挖掘结果第一弹
		  通过可视化，发现一些异常节点，比如可以看到 15262685846，15951125174,这两个电话所有的通话都一样的，这涉嫌了通过同一设备去申请贷款
		  通过查询，发现两个电话分属两个人，但是通话记录一模一样，从这个角度来看，通话记录可以作为设备指纹的一部分，
		  而且还发现，这些通话号码的前缀都是一样的，这些通话记录涉嫌伪造
		  match (p:phone)-[r]->(o)<-[rel]-(ph:phone) where p.id='15262685846' return p,o,ph
		  
		  
	  
	   3 查看借款人之间的关系，关系定义为四度，也就是说拥有共同联系人的申请人  1322012018120606
		match path =(p:person)-[*..4]-(p1:person) 
					WITH path LIMIT 10000 with collect(path) as paths
					call apoc.gephi.add(null,'test', paths) yield nodes, relationships, time
					return nodes, relationships, time
		
		将person的标签映射到gephi，注意第四个参数是关系的权重，也可以取关系的属性做权重，第五个参数是列表，主要传入节点的属性，如果加了单引号默认这个属性是str
		match path =(p:person)-[*..4]-(p1:person) 
					WITH path LIMIT 10000 with collect(path) as paths
					call apoc.gephi.add(null,'test', paths,'weight',['is_black', 'overdue']) yield nodes, relationships, time
					return nodes, relationships, time
					
		对通话次数做限定 两次及以上	
		match path = (p:person)-[a]->(ph:phone)-[rel:called]->(o:phone)<-[r:called]-(ph1:phone)<-[b]-(p1:person) 
		where rel.times > '1' and  r.times >'1' 
		WITH path LIMIT 10000 with collect(path) as paths
					call apoc.gephi.add(null,'test', paths,'times',['is_black', 'overdue']) yield nodes, relationships, time
					return nodes, relationships, time
		
		对通话次数做限定 两次以上，这次是比较强的联系关系
        match path = (p:person)-[a]->(ph:phone)-[rel:called]->(o:phone)<-[r:called]-(ph1:phone)<-[b]-(p1:person) 
		where rel.times > '2' and  r.times >'2' 
		WITH path LIMIT 10000 with collect(path) as paths
					call apoc.gephi.add(null,'test', paths,'times',['is_black', 'overdue']) yield nodes, relationships, time
					return nodes, relationships, time	
		
        纯逾期用户的通话关系		
		match path = (p:person)-[a]->(ph:phone)-[rel:called]->(o:phone)<-[r:called]-(ph1:phone)<-[b]-(p1:person) 
		            where p.is_black = '1' and p1.is_black='1' and rel.times > '1' and  r.times >'1'  
					WITH path LIMIT 10000 with collect(path) as paths
					call apoc.gephi.add(null,'test', paths,'times',['is_black', 'overdue']) yield nodes, relationships, time
					return nodes, relationships, time
					
		挖掘结果第二弹
		存在一些中间节点，很多借口用户都指向了同一个电话，这个中介性很明显了，
		match (p:phone)-[rel:called]->(t:phone)<-[r:called]-(other:phone) return t.id,count(t) order by count(t) desc
					
 2. 团伙挖掘，通过分析借款人之间的直接联系，或者共同的黑中介
				
   4 查看存在直接联系的借款人，关系定义为三度
   match path =  (p:person)-[*..3]-(p1:person) with collect(path) as paths
				call apoc.gephi.add(null,'test', paths) yield nodes, relationships, time
				return nodes, relationships, time
				
   match path =  (p:person)-[r]->(ph:phone)-[rel]-(ph1:phone)<-[a]-(p1:person) with collect(path) as paths
				call apoc.gephi.add(null,'test', paths) yield nodes, relationships, time
				return nodes, relationships, time
				
	将person的标签映射到gephi			
	match path =  (p:person)-[r]->(ph:phone)-[rel]-(ph1:phone)<-[a]-(p1:person) with collect(path) as paths
				call apoc.gephi.add(null,'test', paths,'times',['is_black', 'overdue']) yield nodes, relationships, time
				return nodes, relationships, time
  
  找一下成为中间人的借款人
  match (p:phone)-[rel]->(t:phone)<-[r]-(other) where t.is_loaner='1' return p,t,other
  
  CALL algo.louvain(
  'match (p:phone)-[rel]->(t:phone)<-[r]-(other)
   RETURN id(p1) as source, id(p2) as target, f.times as weight',
  {graph:'cypher',write:true});
  
  
  导出为Graphml文件
  call apoc.export.graphml.query('match (p:person)-[r]-(q:person) where p.community1=1290652 and q.community1=1290652 return p,r,q',
  'C:/Users/Administrator/Desktop/gaomi.graphml',{useTypes:true})
  
    call apoc.export.graphml.query("match path = (p:person)-[a]-(q:person)-[b]-(r:person) where p.is_black='1' or q.is_black='1' or r.is_black='1' return p,a,q,b,r",
  'C:/Users/Administrator/Desktop/black.graphml',{useTypes:true})

4 可视化辅助
  通过gephi来辅助子图的可视化
  对于目前的用户同构网络来说，可以先通过标签转播算法对整个网络进行初步的社区划分，然后对子图进行可视化研究，
  1. 目前对一些同社区的子图进行了OpenOrd的可视化，发现每一个子图基本都有一到一个以上的高密子图，这样的高密子图中
  的特点就是每一个节点都和团内其他很多节点有关系，其实一个高密团体根本不能说这就是欺诈团伙，因为网络中大部分用户
  基本都有拒绝记录，或是根本就没有审核通过的订单，所以一个高密团的整体通过率拒绝率是一个参考的指标，但估计也不能与
  有非常大的区分度
  
 

同构社交网络的研究
   1 网络设计
   这个网络是同构用户网络，我们将通过借贷人之间的直接联系建立网络关系
	# 1 将用户idnum和电话构建字典
	# 2 按日期去查每一个用户的calls，然后遍历calls的电话，从字典中撞，撞到的立即建立通话关系
	# 3 同样的遍历紧急联系人列表撞一次
	# 4 融合好通讯录，遍历通讯录再撞一次
	# 5 寻求通过间接通话关系建立用户之间的连接
	
	# 紧急联系人的这一层筛查，基本没情况，也就是说，用户填写的紧急联系人手机号基本没有去借贷，
	  如果想要用户紧急联系人的话，还是一样需要把所有用户的紧急联系人放入字典，然后那用户所有紧急联系人去撞字典，然后建立连接
	
	
	目前网络有50万节点，我只是将有关系的用户建立了连接，也就是说目前网络中的用户都不是孤立的，但是最终的网络中肯定要讲所有用户都创建进去，
	以便每天的更新，用户节点是全量的。目前跑了150万用户，拿了100数据跑了一下，50万节点写了进去，说明借贷人之间是存在着联系的，目前看来已经
	有小规模社区成形，但是社区数据大给计算上确实带来了难题。
	最终需要将全量用户写入网络，也就是说生产环境中所有用户都在网络中，不管有没有关联关系，因为这个网络是动态的，我们需要不断的更新
	
	match path =  (a:person)-[r]-(b:person)-[q]-(c:person)<-[p]-(d:person) WITH path LIMIT 10000 with collect(path) as paths
				call apoc.gephi.add(null,'test', paths,'times',['nid']) yield nodes, relationships, time
				return nodes, relationships, time
				
	match (p)-[*..3]-(q) where p.nid='511381199307264497' return p,q
	
    call apoc.export.graphml.query("match path = (p:person)-[a]-(q:person)-[b]-(r:person) where p.is_black='1' or q.is_black='1' or r.is_black='1' return p,a,q,b,r",
    'C:/Users/Administrator/Desktop/black.graphml',{useTypes:true})
  
    match path = (p)-[a]-(q)-[b]-(r) where p.nid='511381199307264497' with collect(path) as paths
				call apoc.gephi.add(null,'test', paths,'times',['nid']) yield nodes, relationships, time
				return nodes, relationships, time
				
	两个节点最短路径		
	MATCH p=shortestPath(
            (bacon:person {nid:"00011a11c626fbda93d15348de6290f1"})-[*]-(meg:person {nid:"1dd25cb6d6dcd62904942414b96c93a9"})
     )RETURN p
				
	2 网络涉黑标记
	  1 强标记 催收黑名单
	  2 弱标记 逾期黑名单 pd1,pd3,pd7,M1
	  
	 
	  
	3 线下网络挖掘
		  1 首先需要确定每一个连通分量，对不同的连通分量做社区挖掘，如果都不连通的话，那就没什么联系了
		  利用algo的算法，按照节点的连通性对节点进行分区标记    neo4j可行
		  CALL algo.unionFind('person', '', {write:true, partitionProperty:"partition"})
				YIELD nodes, setCount, loadMillis, computeMillis, writeMillis;
				
		  分区总数：1076119  一个超级分区总结点数：8267503 剩余100多万节点大部分是孤立的
				
		  CALL algo.unionFind('person', '', {graph:'huge',write:true, partitionProperty:"partition"})
			YIELD nodes, setCount, loadMillis, computeMillis, writeMillis;
		 
		 # 通过标签传播算法分区  neo4j可以实现
		  CALL algo.labelPropagation('person', 'call','BOTH',
		  {iterations:10,partitionProperty:'community', write:true})
		YIELD nodes, iterations, loadMillis, computeMillis, writeMillis, write, partitionProperty;
		
		CALL algo.labelPropagation('person', 'connected','BOTH',
		  {iterations:10,partitionProperty:'community1', write:true})
		YIELD nodes, iterations, loadMillis, computeMillis, writeMillis, write, partitionProperty;
		
		社区总数： 2298889 社区人数大于10： 96147   社区人数大于100：c_100 5757
		   
		  
		  2 确定不同分区之后，按社区节点多少降序排序，开始对分区进行社区算法的研究，具体：
			  可以通过排序，查看各个社区节点数目
			  MATCH (u:person)
				RETURN u.partition as partition,count(*) as size_of_partition
				ORDER by size_of_partition DESC
				LIMIT 20;
				
			match path = (p:person) where p.partition=397375 with collect(path) as paths
				call apoc.gephi.add(null,'test',paths) yield nodes, relationships, time
				return nodes, relationships, time
				
			match path = (p:person)-[r]-(q)-[a]-(o)-[b]-(c)-[d]-(e) where p.partition=1061384 WITH path LIMIT 30000 with collect(path) as paths
				call apoc.gephi.add(null,'test',paths) yield nodes, relationships, time
				return nodes, relationships, time
			# 统计
			match (p:Phone)-[r]-(q) return r.nid,count(r.nid) as c_c order by c_c desc limit 200
				
			查看异常社区的每个电话关联的用户人数并降序排列输出
			match (p:Phone)-[r]-(q) where p.partition = 471749 return p.nid,count(q) as c_c order by c_c desc limit 100
			
			查看异常社区的name出现的个数并降序排列输出
			match (p:Phone)-[r]-(q) where p.partition = 471749 return r.name,count(r.name) as c_c order by c_c desc limit 100
			match (p:Phone)-[r]-(q) where p.partition = 471749 return r.relation ,count(r.relation) as c_c order by c_c desc limit 100
				
		  3 高密子图挖掘
			群控设备，猫池等等欺诈团体使用的批量身份证和手机号，如果是盗用身份和手机号，这个比较难以检测，如果这些手机号
			是批量的假号，这些手机号的通话记录是没办法造假的，养号的套路是假号互相通话，营造出一种正常通话的感觉，但是在网络中
			这些假号码的最大特征就是互相之间联系密切，会形成高密子图，虽然这么说，但是根据通话构建的网络普遍连接是一个大的连通图，
			高密子图存在而且普遍存在，怎么辨别出那个子图是欺诈团体，哪些是中介团体，哪些是正常的团体呢，这个比较麻烦。
			针对目前通话网络，需要去验证一下，高密子图的整体的一个通过，逾期，涉黑情况，
			如果高密子图的这些指标高于平均指标的话， 那通话网络是有欺诈检测的潜力在里面的。
			
			pylouvain算法   Q就是模块度，模块度越大则表明社区划分效果越好。Q值的范围在[-0.5,1），论文表示当Q值在0.3~0.7之间时，说明聚类的效果很好
			通过pylouvain算法对现有社区进一步进行社区划分，然后对每一个社区进行一些指标的统计，来探索一些欺诈情况
			统计指标：总体特征：团体节点数量，团体放款金额，团男女比例，最大年龄差
			          平均特征：平均度，平均年龄，平均的申请，通过，逾期次数，放款金额，最大逾期天数
					  比率特征：通过率，逾期率，
			
		  4 欺诈标注传播
			通过催收黑名单，逾期用户，设置欺诈用户名单，标记网络并利用trustrank算法将涉黑标注传播开来
			创新之处，利用马尔科夫链进行迭代，通过通话时长和通话次数不同权重的来确定最终关系的权重值，利用转移矩阵来
			实现：spark graphx
			
		  5图挖掘
			 1 network embedding
				 deepwalk：1 random walk   2 wordtovec
				 目前针对小规模网络比如karate做测试：
						 1 feature：网络节点特征的提取： 1 邻接矩阵， 2 邻居vote， 3 randomwalk+word2vec 4 GCN

						 2 model： 模型的选取就比较弹性了，sklearn系列的很多，目前试了，SVM，K邻近算法，K邻近在deepwalk的特征下面有非常好的表现	
						 接下来，可以尝试更多的模型试试deepwalk的特征怎么样
						 
				 对于网络嵌入来说，主要工作就是提取图信息嵌入节点特征，模型其实影响好像没有那么大
				 
			 
			 除了可视化进行初步的调研之后，我们应该选取一些有代表性的社区去跑deepwalk，GCN试一试
				 1. 将社区转化为图数据。
				 2. 分别尝试将社区所有节点本身历史借贷特征和图embedding特征跑出来
				 3. 尝试应用聚类算法进行高密子图拆分
				
				 
				目前针对用户网络中选取的一个社区做了deepwalk测试，最终将学到的表示向量降维到二维，可以达到和gephi同样的效果，
				 证明deepwalk确实可以学习图结构信息，但是如何将这种算法应用到真实业务场景中去，目前还是未知，
				 至于社区中节点的历史特征没有聚类的意义，

				 
			 2 gcn
			   1 卷积神经网络学习
			   2 tensorflow使用或是pytorch使用
			   3 搭建模型
			   
	
	4 网络监控
	  随着新进件用户的数据更新到网络，监控网络的动态变化，比如一些社区的闭合
	  
	5 推出网络变量线上服务
	      社交网络一大优势就是网络变量输出，我认为有两大类变量可以输出：
		  1 节点本身的金融属性特征
		       目前已经上线的特征主要有，当前节点一度联系人最大和平均两个维度的用户申请，拒绝，通过，逾期次数，天数的特征
			   效果： KS和AUC都有明显的提高，平均提高5个百分点
		  2 图结构特征：社区，团，边
		        团节点数，度，紧密程度维度
				团内性别占比，地区分布
				团内边属性聚合，比如通话次数，通话时长
		       
		  对新进件的用户的运营商数据进行网络更新和查询，输出一阶二阶用户变量，涉黑情况
		  1 比如一度联系人中有多少黑中介，一度联系人中的逾期人数有多少，此类特征的KS较高且有效
			联系强度: 根据两个号码之间通话频次、周期性、主被叫关系等来判断两个号码之间紧密的程度，用于衡量两个人之间可以互相影响的程度
			有效联系人: 联系强度达到某个特定值以上的联系人
			
		  2 网络变量可以衍生出很多，比如说，社区人数,男女比例
			1 团内其他用户的表现，比方说逾期率、通过量等。这一特征判断的核心思想可以归纳为“近朱者赤，近墨者黑”。
			这些特征现有的接口就可以提供，社团内的其他节点或是一阶相邻节点的申请，通过，拒绝，逾期，放款量这些特征都可以访问接口实现
			2 团本身的特性，比方说节点数、团内用户的连接紧密程度等，还有其他一些节点度量数据。
			团内用户的属性，比方说团内的女性人数、地区分布、平均借款额度，申请次数等。一般而言，团内女性人数占比越大，团内用户是“好人”的概率就越大。
			
		  改进的点： 同构网络中应该将用户的创建时间写入用户节点，这样做的意义是，通过某一节点查询一度二度联系人时有时间回溯的概念在里面
		             就是说，当我们用于线下训练时，我们获取当前节点的一度联系人应该去找到当前节点入库时间节点之前的其他邻居节点，
					 而不是所有节点，因为有可能其中一些节点是在这个用户之后入库的，从时间回溯的角度看，这个人此时是不存在的
		  只要有了用户的基础特征大概几千维左右，那么根据一度二度联系人，可以衍生出同样维度的网络特征
		  比如根据当前订单查到了该用户，我们只需要携带该订单的创建时间，去网络中寻找其他节点的所有订单，然后拿到其他用户在这个创建时间之前的订单
		  通过这些订单可以去特征库中查到社交网络中其他用户的基础特征，然后就可以做处理，比如聚合等等
		  
	  
	6 网络定时更新
	  对于同构用户网络，可以采用每天定时任务同步，t-1天新增用户到网络
	
  2接入其他网络关系
    1 wifi数据，一般群控设备用wifi可以很好的发现，这些设备的wifi是一致的
	
	
  3 生产环境的网络构建和服务
    把社交网络当成一个服务平台，为其他部门提供网络数据服务。
	1 网络构建问题
	  全量数据需要进入网络，这样的情况下，需要将当前所有用户数据进入网络，
	  思路是讲所有用户id和电话号码组成字典放入redis，然后利用多线程或是多进程快速建立全量网络
	2 网络更新问题
	  1 实时同步：每当一个新的进件进来，调用一次网络变量服务，如果此用户在网络中不存在，创建新用户和新关系
	  2 定时任务：可以采用每天定时任务同步，t-1天新增用户到网络
	  
	3 网络变量输出问题
	
  4 开发过程中的难题
    整个过程主要分为两步，第一步是电话，身份证建立字典，然后读取每一个人的通话记录，紧急联系人，通讯录，去字典撞一遍。
	第二步，将撞到的数据，存入neo4j建立关系。
	第一个过程采用分页读取，可以很好的提高查询速度，
	第二步因为每插入一个节点都需要查询其是否存在，这个过程成了速度瓶颈
	测试环境：将该构造的节点不重复的写入文件，将全部关系也写入文件，然后读取文件直接创建节点和关系，将所有需要创建的节点统计出来直接在neo4j创建
	生产环境：在构建字典的时候可能将全量用户写进网络，在撞数据时只写入关系
	
	最终还是使用neo4-import 导入数据，单条插入速度超级neo4j-admin import --nodes some_path_to／node.csv --relationships some_path_to/rel.csv慢
	用neo4-import导入，需要将导入节点和关系先写成csv文件，然后快速导入
	先关闭neo4j，删除graph.db，然后进入cmd，转入bin目录
	执行 neo4j-admin import --nodes D:\Develop\test\neo4j_data\user_whole\nodes.csv --relationships D:\Develop\test\neo4j_data\user_whole\rels.csv
	    neo4j-admin import --nodes D:/develop/data/network/whole_data/node_all.csv --relationships D:/develop/data/network/whole_data/rel_all2.csv
		
    如果出现导入错误，输入neo4j-admin import 会提示解决办法，主要看--ignore
	--ignore-extra-columns
	--ignore-missing-nodes
	--ignore-duplicate-nodes
	
	--ignore-empty-strings
	
	neo4j-admin import --nodes D:/develop/data/network/emer_data/whole_node_pro.csv --relationships D:/develop/data/network/emer_data/whole_rel_clear.csv
	--ignore-extra-columns
	--ignore-missing-nodes
	--ignore-duplicate-nodes
	    
	  
	  
反欺诈同构网络
    现有的问题是通话同构网络比较稠密，干扰性较大，很难将欺诈团伙和正常团伙区别开来，主要是因为其实通话关系本身是弱欺诈属性，
当然我也想了，一些欺诈团伙可能互相之间联系紧密，但是我发现高密子图非常多，这些子图的用户从借贷情况来看，
并没有很好的把逾期的人群给区别出来，故而考虑了另一种构建方案：
    这一次网络关系将引入欺诈属性比较强的关系，盘点一下：设备，wifi，IP，imie，以及共用手机号，以及共用紧急联系人，
将这些强属性关系作为评价，构建一个同构网络，看看网络的情况，如果太洗漱估计也没啥用。如果可以广泛联系，或是成团，那么欺诈检测的
这种事就可以很容易搞了。	
	
						

CALL algo.pageRank(
  'MATCH (p:person) RETURN id(p) as id',
  'MATCH (p1:person)-[rel]-(p2:person) where p1.partition=372809 and p2.partition=372809 RETURN id(p1) as source, id(p2) as target',
  {graph:'cypher', iterations:5, write: true}
)

社交网络是基于平台自有数据，对用户之间潜在的关联关系进行挖掘，对用户关联关系进行网络建模，从而形成的有一定规模的无标度的复杂网络。
社交网络主要作用有两大块。第一进行反欺诈识别，第二进行网络特征输出。
这里主要讨论网络的构建方法与网络特征的输出。

网络构建方案：
业内主流的网络构建方案为利用用户通话记录，通讯录，紧急联系人等数据，以通话，通讯录，互为紧急联系人为关联关系构建，以电话，用户等实体作为网络节点来构建社交网络。比较知名的如聚信立，拍拍贷等公司。
社交网络用作特征输出，需要满足的一个必要条件就是，网络要足够稠密，如果网络关系过于稀疏，那么网络特征的命中率就会大大降低，遂失去了入模的意义。网络结构必须足够精简，设想将用户通话记录，通讯录中电话作为网络节点，那么网络规模将是百亿级别的节点，网络由于引入过多干扰信息，变得臃肿不堪，网络的维护成本以及网络变量输出的难度加大，猛犸反欺诈通过对网络节点的折叠实现结构简化，但是其他一些公司主要以反欺诈为主要的应用目的。
我们的社交网络的构建思路与其他公司不同的地方在于利用公司积累的大量用户数据挖掘信贷用户之间的关联关系。
1.统一网络节点以及关系类型，这样做的目的是，有利于网络特征输出。有利于高阶图算法的开展，异构网络的图挖掘是业内难题。
2.精简通话通讯录关系，只保留本平台用户关联数据，其结果直接导致网络规模降低，维护挖掘成本降低，从最终结果看，网络仍然是稠密的，满足特征挖掘的条件。

网络数据存储方案
业内较为流行的图数据库为neo4j，社区版免费使用，支持百亿级别的网络规模。其优点是查询速度快，可以较好的支持实时网络数据查询，有一定的可视化插件支持，有一定的图算法插件支持，但是由于业务的特异性，内嵌算法很难进行应用，需要二次开发，本次产品的选用是neo4j。

网络数据挖掘
1.网络结构方向
    度统计
环检测
    社区检测(louvain,图表示学习，图神经网络)
  
2.网络节点方向
   1初级挖掘
    一阶，二阶，社团群体画像，包括性别，年龄，地址，职业等等画像特征，从社会面貌，经济水平，贷后表现等层面刻画群体用户。
   2进阶挖掘
    利用图表示学习，GCN等前沿算法探索网络结构，对群体特征进行高阶传播和衍生。
     
3.结构与节点
   利用关系权重对群体进行分层，利用权重对特征进行衍生。
   
紧急联系人网络构建与挖掘
1.设计方案
通过平台积累的紧急联系人数据，利用互为紧急联系人，共用紧急联系人等关系构建以电话号码和用户为网络节点的社交网络
2. 网络情况
从最终的构建结果看，全量的数据之下，用户1600w，电话节点5000w左右，网络中存在大量的互用共用紧急联系人电话的情况，
自发的形成了自连通的社区，其中有一个超级大社区，广泛存在多人共用同一个电话号码作为紧急联系人号码，而且此电话号码不是个人号码

3.特征挖掘
  *经过对用户紧急联系人数据的稳定性，已经经过网络关联的一些互斥校验，常规统计最终的特征有50维左右，大概20个特征是比较有效的
   作为规则来说都很强，入模也有很好的效果
  * 用户特征库更新完成之后，引入用户征信报告强特征，在加上局部的强特征融合，以及稳定性，互斥校验等等特征，最终可以训练子模型对网络用户
    给出信用或是欺诈评分
	
4. 高阶特征挖掘
   rong360通过对用户点击序列做词向量表征，探索用户点击行为潜在的模型，可以将坏用户的一些共同模型检测出来
   对应图数据来说，图结构也可以转化为序列数据，例如deepwalk就是通过随机游走加word2vec，学习了图的图向量表征
   在对于用户社交网络来说，我认为用户的图结构并不能表征用户的一些潜在的模式，互相之间的这种通话结构可以体现一个人的欺诈风险吗
   其实也不好说，不过对于紧急联系人网络来说，不同的用户拥有不同的手机个数，存在共用，可以尝试去预训练网络节点的词向量出来，入模评估一下
   
   效果不太好，观察了一些随机游走之后的节点序列，不太能够区分一些结构不同的节点，这里准备干预随机游走的策略
   几个统计结果，用户节点关联的电话号码个数平均数是4， 44%的用户节点有关联用户
   
5. 高阶特征挖掘2
   其实网络的这种结构是完全可以转化为序列数据的，通过随机游走的方式来表示潜在的网络机构，序列数据可用的模型，尤其是深度模型很多的，
   其实自然语言处理的很多深度学习模型都可以套用的图上来，可以先将图的嵌入向量预训练出来，用户备用特征
   
   1.cnn 探索特征的组合，可以通过卷积操作提取特征潜在的高阶表征，这里输入层即可以是普通特征又可以是嵌入向量，Text CNN的输入就是词向量
   
   2. 直接利用textCNN或是其他文本分类模型对节点进行分类
   
deepwalk neo4j 相关 https://neo4j.com/blog/deepwalk-implementing-graph-embeddings-in-neo4j/
