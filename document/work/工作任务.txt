
工作任务

network
	1 同步全量社交网络任务
		1 线下数据，选定时间点，将新用户相关数据导入mongodb
		2 全量跑一边mongodb，生成数据文件
		    5.8号 全量用户和电话数据写入文件，统计结果，金盘用户数据量 13567610 身份证不重复且有电话号码的：13162441
			其中有297501用户与其他用户共用了电话所以数据对不上 ，这样下来共用手机号的用户占比大概有三个百分点
		3 将文件导入neo4j
		4 线上同步任务开发
	
	
	反欺诈
    1 针对目前通话网络，需要去验证一下，高密子图的整体的一个通过，逾期，涉黑情况，
	如果高密子图的这些指标高于平均指标的话， 那通话网络是有欺诈检测的潜力在里面的。
	
	2 资源网络： 这一次网络关系将引入欺诈属性比较强的关系，盘点一下：设备，wifi，IP，imie，以及共用手机号，以及共用紧急联系人，
		将这些强属性关系作为评价，构建一个同构网络，看看网络的情况，如果太稀疏估计也没啥用。如果可以广泛联系，或是成团，那么欺诈检测的
		这种事就可以很容易搞了。

	图算法
	embedding无监督分类，检测高密子图
	gcn使用
	
	紧急联系人数据挖掘
	1  对于个人紧急联系人历史数据，可以即时建立一个由电话号码，电话名称，电话关系组成的小网络，可以实现不一致校验，也可以衍生很多特征

	2 对于全量紧急联系人数据，可以建立一个由电话，姓名，关系组成的异构网络，同样可以识别一些欺诈，也可以衍生一些特征

	3 讲紧急联系人网络折叠可以进入用户同构网络，做强关联补充，增强同构网络的表征能力
	
feature
   jinpan 特征标准化
   时间维度运营商特征开发
   CNN特征衍生
----------------------------------------------------------------------------------   
20190701 
1 迁移历史特征到评分卡模型，重新设计历史特征

 1住址变换指标，设备变换，公司变换，紧急联系人变化

 2申请时间指标：集中度，分散度，
   前后订单的申请时间间隔的平均值以及方差
   将时间间隔分类，并统计各个分类占比，一天，一小时，一分钟之内的申请次数
   
   
 3机构迁移指标

 4历史借贷指标
	1 monthly: 按月维度
	2 dayily：按一天的时间将订单分为不同类别
	3 weekly： 将订单分为周末非周末
	  分别：apply approve reject,pd0,pd7,pd14,loan_amount,max_overdue,avg_overdue
	  
	对于分期来说：首逾，连续逾期的情况要体现出来
	对于逾期的计算： 分为通过逾期，通过不逾期，无通过无逾期：-3
	
	申请订单序列，体现连续情况，连续通过，连续拒绝，
	
 5 近期其他机构的申请申请情况
 
 6 住址，公司，手机号，设备，紧急联系人稳定性指标
    1对于住址，公司名称，公司地址，分别统计不重复地址个数，真实地址个数及其占比
	2对于紧急联系人历史数据，主要统计
	     1 不同电话号码下的联系人姓名，关系个数，期望，方差，众数的常用指标
		 2 不同姓名下的电话号码个数，期望，方差，众数的常用指标，这个主要为观察紧急联系人的电话号码变动情况
		 4 紧急联系人关系的不一致校验，对同一人的称呼存在的矛盾进行观测，比如{'18065373997': {'父亲', '朋友', '父母', '直亲', '母亲'}
		   即是父亲又是母亲这种明显的矛盾
	     3 通过观察时间序列上的紧急联系人数据，比对前后两次申请的紧急联系人数据的变化情况，挖掘指标来量化这种变化情况
 
 7 社交网络特征
   所有个人特征，都可以衍生到一度或多度联系人上面，这里主要分两个方向
   1,一度联系人的历史借贷特征
   2 一度联系人图卷积聚合特征
   3 从个人用户的其他有效特征拓展到一度联系人的特征上面
       目前：近60天内被叫duration超过1，2，3分钟，10秒的count占比
	         mobile_use_days等等，也就是可以把当前节点和周围节点的运营商，以及其他连七八糟的只要是有用的特征用图卷积的方式聚合起来就行
     
	

2 迭代金盘feature特征，并加入社交网络共用号码的命中情况

--------------------------------------------------------------------------------

model
  1 秒啦首贷模型
    1 从地址数据挖掘特征
	   方案：1, 按照区域申请，通过，逾期的情况打标签
			 2, 按照地址属性打标签，比如一下模糊地址，虚假地址
			 3, 按照区域放款量来打标签
			 
			 区域粒度：暂定区县为最小区域 
			 
		
		内容：通过对地址数据分词，进而统计每个区域的历史订单情况，给出区域的通过，逾期等指标，预统计在内样本200万，最后生成地域指标字典 历史订单数量 11399239 地址不空 5629378 有历史表现 4760009
		
		开发过程：
		1， 收集jinpan用户历史特征，以及用户的住址数据
		2， 对地址数据进行简单清洗，然后进行文本分词
		3， 将用户全量历史表现情况映射至地址层面，地址的拆分目前定为4层分别为：prov，city, country, area
		4,  历史表现指标包括申请比，通过比，逾期比，放款均额，以及 pd3，pd7，pd14，M1, M2, M3等指标
		5， 最终地址特征取地址分层和历史表现指标的笛卡尔积，通过秒啦用户地址数据解析出地址相关变量80个
		
		结果
		             AUC	KS
		训练集	0.841367	0.424051918505
		验证集	0.581202	0.120599640354
		跨时间  0.556192	0.105703250928
		
		结论： 住址文本数据对逾期情况预测能力较弱，有一定预测能力,主要表现在县区粒度的均放款金额，结果表明在不同区域的流入金额与逾期情况存在一定的相关性。
		
		存在的问题：
            地址数据不够规整，清洗难度较大，这影响了不同区域的指标统计结果的准确性，潜在的解决方案是通过NLP对地址数据上下文进行预测补充。
		 
		地址数据特征的后续工作：
			淘宝地址数据，身份证地址数据，可以调用相同的函数来得到相应的地址特征，结果有待验证


			 
    2 从applist挖掘特征
	    方案： 1 对app数据做LAD主题子模型
		       内容：1 尽量提取足够多的用户app数据，将app数据分词组装词袋
			         2 创建语料的词语词典，每个单独的词语都会被赋予一个索引
					 3 将语料变成 DT 矩阵，即给每一个词一个编号，并且给出这个词的词频
					 4 指定主题数，训练主题模型，模型将得到指定数量的主题集合，将模型数据保存
					 5 读入模型数据，读入待预测app数据，得到该文本的分属不同主题的概率值作为特征
					 6 组装特征数据进行特征评估
					 
		结果：开发过程分为两部分，我分别用秒啦首贷的app数据约8w的词和金盘的大约15w的词作为语料来训练LDA
		      1，秒啦app数据下的LDA模型预测的特征表现
			     预测峰值对应的主题数范围在250--350之间，AUC表现稳定在0.6左右
			  
			  2，jinpan app数据下的LDA表现
			     对比秒啦语料，从整体看模型的效果得到了提升，验证测试集表现相对稳定，app语料的丰富对模型的预测效果有一定的提升作用，
				 当主题数[70,90]的范围内，测试集上的AUC的峰值均曾达到0.62
		    
					 
	   
	
	
model2
    嘉卡模型： 原模型：1,运营商模型， 2 运营商+新颜
	           新模型：运营商+新颜+jinpan2.0+新运营商+第三方+文本特征    对照组：运营商+新颜
	数据：嘉卡全量，去年到今年6月份21w数据
			   
			内容：1 获取标签以及原始数据21w
			      2 获得老特征
				  3 获得新特征
				      jinpan特征获取：通过外部订单号获得金盘对应的订单时间以及其idnum，然后通过时间回溯接口跑出对应特征
                    				  
				  4 训练模型，对比结果
	
	使用更多模型在金盘特征上面，xgb，gbdt，lightGBM等等
	运营商特征上尝试使用无监督分类方法
	
data
    金盘数据迁移至TiDB
	
	解析征信报告
	
	
	