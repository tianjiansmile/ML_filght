
工作任务

network
	1 同步全量社交网络任务
		1 线下数据，选定时间点，将新用户相关数据导入mongodb
		2 全量跑一边mongodb，生成数据文件
		    5.8号 全量用户和电话数据写入文件，统计结果，金盘用户数据量 13567610 身份证不重复且有电话号码的：13162441
			其中有297501用户与其他用户共用了电话所以数据对不上 ，这样下来共用手机号的用户占比大概有三个百分点
		3 将文件导入neo4j
		4 线上同步任务开发
	
	
	反欺诈
    1 针对目前通话网络，需要去验证一下，高密子图的整体的一个通过，逾期，涉黑情况，
	如果高密子图的这些指标高于平均指标的话， 那通话网络是有欺诈检测的潜力在里面的。
	
	2 资源网络： 这一次网络关系将引入欺诈属性比较强的关系，盘点一下：设备，wifi，IP，imie，以及共用手机号，以及共用紧急联系人，
		将这些强属性关系作为评价，构建一个同构网络，看看网络的情况，如果太稀疏估计也没啥用。如果可以广泛联系，或是成团，那么欺诈检测的
		这种事就可以很容易搞了。

	图算法
	embedding无监督分类，检测高密子图
	gcn使用
	
	紧急联系人数据挖掘
	1  对于个人紧急联系人历史数据，可以即时建立一个由电话号码，电话名称，电话关系组成的小网络，可以实现不一致校验，也可以衍生很多特征

	2 对于全量紧急联系人数据，可以建立一个由电话，姓名，关系组成的异构网络，同样可以识别一些欺诈，也可以衍生一些特征

	3 讲紧急联系人网络折叠可以进入用户同构网络，做强关联补充，增强同构网络的表征能力
	
feature
   jinpan 特征标准化
   时间维度运营商特征开发
   CNN特征衍生
----------------------------------------------------------------------------------   
20190701 
1 迁移历史特征到评分卡模型，重新设计历史特征

 1住址变换指标，设备变换，公司变换，紧急联系人变化

 2申请时间指标：集中度，分散度，
   前后订单的申请时间间隔的平均值以及方差
   将时间间隔分类，并统计各个分类占比，一天，一小时，一分钟之内的申请次数
   
   
 3机构迁移指标

 4历史借贷指标
	1 monthly: 按月维度
	2 dayily：按一天的时间将订单分为不同类别
	3 weekly： 将订单分为周末非周末
	  分别：apply approve reject,pd0,pd7,pd14,loan_amount,max_overdue,avg_overdue
	  
	对于分期来说：首逾，连续逾期的情况要体现出来
	对于逾期的计算： 分为通过逾期，通过不逾期，无通过无逾期：-3
	
	申请订单序列，体现连续情况，连续通过，连续拒绝，
	
 5 近期其他机构的申请申请情况
 
 6 住址，公司，手机号，设备，紧急联系人稳定性指标
    1对于住址，公司名称，公司地址，分别统计不重复地址个数，真实地址个数及其占比
	2对于紧急联系人历史数据，主要统计
	     1 不同电话号码下的联系人姓名，关系个数，期望，方差，众数的常用指标
		 2 不同姓名下的电话号码个数，期望，方差，众数的常用指标，这个主要为观察紧急联系人的电话号码变动情况
		 4 紧急联系人关系的不一致校验，对同一人的称呼存在的矛盾进行观测，比如{'18065373997': {'父亲', '朋友', '父母', '直亲', '母亲'}
		   即是父亲又是母亲这种明显的矛盾
	     3 通过观察时间序列上的紧急联系人数据，比对前后两次申请的紧急联系人数据的变化情况，挖掘指标来量化这种变化情况
 
 7 社交网络特征
   所有个人特征，都可以衍生到一度或多度联系人上面，这里主要分两个方向
   1,一度联系人的历史借贷特征
   2 一度联系人图卷积聚合特征
   3 从个人用户的其他有效特征拓展到一度联系人的特征上面
       目前：近60天内被叫duration超过1，2，3分钟，10秒的count占比
	         mobile_use_days等等，也就是可以把当前节点和周围节点的运营商，以及其他连七八糟的只要是有用的特征用图卷积的方式聚合起来就行
     
	

2 迭代金盘feature特征,引入整体统计指标，主要为区别个人与整体情况的差异
  对于个人历史特征的统计，之间局限于比如近7天通过次数，通过比率，
  通过比率是：通过次数/申请次数，比值局限于个人的总体申请情况，这一次进入全库总体统计指标
  比如 近7天申请次数/近7天整体平均申请次数   个人申请次数/总体平均次数，总之就是查看个人各个指标与总体平均指标的差异
  
  对于盘智项目来说，
      第一道模型风险评估模型，靠前特征为interval相关特征，标签为当前订单的产品类型，根据用户历史申请轨迹
  推测用户风险类型，pdl用户和分期用户的interval特征差异是最大的，排名靠前也就不奇怪了，
  可以加入用户分期pdl申请比，申请产品稳定性指标来做。
      第二道标准分模型：金盘靠前特征则为近90内所有时间切片申请拒绝次数，这次加入整体统计指标，稳定性指标
  
  解决方案：
  1 根据历史数据时间范围，按照时间轴把每天的平均申请次数和平均拒绝次数算出来然后以映射表的形式存储
    这样做的原因在于，pdl客群变化多端，不同时间的样本个体就应该和对应时间段的整体样本去比较，这样可以满足时间回溯问题，

--------------------------------------------------------------------------------

model
  1 秒啦首贷模型
    1 从地址数据挖掘特征
	   方案：1, 按照区域申请，通过，逾期的情况打标签
			 2, 按照地址属性打标签，比如一下模糊地址，虚假地址
			 3, 按照区域放款量来打标签
			 
			 区域粒度：暂定区县为最小区域 
			 
		
		内容：通过对地址数据分词，进而统计每个区域的历史订单情况，给出区域的通过，逾期等指标，预统计在内样本200万，最后生成地域指标字典 历史订单数量 11399239 地址不空 5629378 有历史表现 4760009
		
		开发过程：
		1， 收集jinpan用户历史特征，以及用户的住址数据
		2， 对地址数据进行简单清洗，然后进行文本分词
		3， 将用户全量历史表现情况映射至地址层面，地址的拆分目前定为4层分别为：prov，city, country, area
		4,  历史表现指标包括申请比，通过比，逾期比，放款均额，以及 pd3，pd7，pd14，M1, M2, M3等指标
		5， 最终地址特征取地址分层和历史表现指标的笛卡尔积，通过秒啦用户地址数据解析出地址相关变量80个
		
		结果
		             AUC	KS
		训练集	0.841367	0.424051918505
		验证集	0.581202	0.120599640354
		跨时间  0.556192	0.105703250928
		
		结论： 住址文本数据对逾期情况预测能力较弱，有一定预测能力,主要表现在县区粒度的均放款金额，结果表明在不同区域的流入金额与逾期情况存在一定的相关性。
		
		存在的问题：
            地址数据不够规整，清洗难度较大，这影响了不同区域的指标统计结果的准确性，潜在的解决方案是通过NLP对地址数据上下文进行预测补充。
		 
		地址数据特征的后续工作：
			淘宝地址数据，身份证地址数据，可以调用相同的函数来得到相应的地址特征，结果有待验证


			 
    2 从applist挖掘特征
	    方案： 1 对app数据做LAD主题子模型
		       内容：1 尽量提取足够多的用户app数据，将app数据分词组装词袋
			         2 创建语料的词语词典，每个单独的词语都会被赋予一个索引
					 3 将语料变成 DT 矩阵，即给每一个词一个编号，并且给出这个词的词频
					 4 指定主题数，训练主题模型，模型将得到指定数量的主题集合，将模型数据保存
					 5 读入模型数据，读入待预测app数据，得到该文本的分属不同主题的概率值作为特征
					 6 组装特征数据进行特征评估
					 
		结果：开发过程分为两部分，我分别用秒啦首贷的app数据约8w的词和金盘的大约15w的词作为语料来训练LDA
		      1，秒啦app数据下的LDA模型预测的特征表现
			     预测峰值对应的主题数范围在250--350之间，AUC表现稳定在0.6左右
			  
			  2，jinpan app数据下的LDA表现
			     对比秒啦语料，从整体看模型的效果得到了提升，验证测试集表现相对稳定，app语料的丰富对模型的预测效果有一定的提升作用，
				 当主题数[70,90]的范围内，测试集上的AUC的峰值均曾达到0.62
		    
					 
	   
	
	
model2
    嘉卡模型： 原模型：1,运营商模型， 2 运营商+新颜
	           新模型：运营商+新颜+jinpan2.0+新运营商+第三方+文本特征    对照组：运营商+新颜
	数据：嘉卡全量，去年到今年6月份21w数据
			   
			内容：1 获取标签以及原始数据21w
			      2 获得老特征
				  3 获得新特征
				      jinpan特征获取：通过外部订单号获得金盘对应的订单时间以及其idnum，然后通过时间回溯接口跑出对应特征
					  extend_info特征：5700维，主要内容
					        
				  4 训练模型，对比结果
	
	使用更多模型在金盘特征上面，xgb，gbdt，lightGBM等等
	运营商特征上尝试使用无监督分类方法
	
	
extend_info特征：5700维，主要内容盘点
	运营商报告特征 
	 1 运营商报告通话特征 'cell_operator_zh'：运营商中文名称, 'net_flow'：流量, 'call_out_time'：呼出时长, 'cell_operator'：：运营商名称, 
	                 'call_in_cnt'：呼入次数, 'cell_phone_num'：电话号码,
                     'sms_cnt'：短信次数, 'cell_loc'：电话归属地, 'call_cnt'：通话次数, 'total_amount', 'call_out_cnt'：呼出次数, 'call_in_time'：呼入时长
		
	  去过去6个月，按每个月统计，总计 72维
	  文本类特征：cell_operator_zh，cell_operator，cell_phone_num，cell_loc
	  
	 2  运营商报告审查  court_blacklist：法院黑名单 ，financial_blacklist：金融黑名单 ，website：号码归属地 ，check_idcard：与运营商身份证是否匹配，reliability：是否实名认证，
	                    diff_reg_time：前后审查时间间隔，check_name：与运营商姓名是否匹配，webcheck_ebusinesssite：是否被网络审查，ls3_operator_addr：运营商联系地址
		共20多维				
		website ，check_idcard，check_name，reliability，webcheck_ebusinesssite，ls3_operator_addr
		
	 3 运营商行为特征 20多维 全为数字类特征
	 
	 4 运营商通讯录特征 
	            'contact_name', 'needs_type',
                'contact_all_day', 'contact_early_morning', 'contact_morning', 'contact_noon',
                'contact_afternoon', 'contact_night',
                'call_in_len', 'call_out_len', 'call_len',
                'call_in_cnt', 'call_out_cnt', 'call_cnt',
                'contact_1w', 'contact_1m', 'contact_3m', 'contact_3m_plus',
                'phone_num', 'phone_num_loc', 'p_relation',
                'contact_weekday', 'contact_weekend',  'contact_holiday'
				
	    去各个维度序列的常规统计指标：最大值，最小值，均值，中位数，众数，方差，总和,共几百维
		needs_type和不同行业的联系情况做one-hot几十维，
		ratioOfCnt_needsType和不同行业的联系情况比率做one-hot几十维
		cnt_phoneNumLoc 和不同地区联系情况one-hot，百维左右
		ratioOfCnt_phoneNumLoc和不同地区联系比率情况one-hot，百维左右
		
	5 运营商报告main_service  
		'total_service_cnt'：总体联系情况 最大值，最小值，均值，中位数，众数，方差，总和,共几百维
		 company_type：和不同类型公司联系情况one-hot
		 ratio_company_type
		'company_name'：和不同类型公司联系情况比率one-hot
	
	6 运营商通讯录地区特征
	   'region_avg_call_out_time', 'region_call_in_time_pct', 'region_call_out_cnt_pct',
                'region_call_out_time_pct', 'region_call_in_time', 'region_avg_call_in_time', 'region_call_in_cnt_pct',
                'region_call_out_time', 'region_call_out_cnt', 'region_call_in_cnt', 'region_uniq_num_cnt'
		对不同地区的上述指标分别做one-hot，2千维数据
		
	7 运营商报告出行特征  tripInfo
	  u'双休日', u'节假日', u'工作日'出行次数，比率，总出现次数
	  trip_diff_time：出行时间差值序列的常规统计指标
	  
	8 用户身份审查 userInfoCheck
	                'phone_with_other_idcards', 'phone_with_other_names', 'register_org_cnt', 'arised_open_web',
                    'searched_org_cnt', 'idcard_with_other_phones', 'searched_org_type', 'register_org_type',
                    'idcard_with_other_names'
					
	9 第三方分属 score
	
	10 探知数据
	   'refInfos', 中间有多项离散单项字母
	   'platform_Infos'： 几十维 数字类
	   'eveSums' 数字类
	   mb_infos：几百维左右，中间有多项离散单项字母
	   
	11 tongdundata数据
	rulesDetail: 数字类
	policySet 离散文本，其中有一些特征的数据中可能包含敏感字符比如 EI_tongdundata_policySet_pname欺诈行为_网站_riskType EI_tongdundata_risk_type 含有,
	hitRules：数字类
	
	EI_tongdundata_final_decision：文本
	
	12 tongdunguarddata
	全部数字
	
	
	最终统计结果： 518左右的文本类特征 
	              其中 EI_nifadata_loanamt，EI_score_友盟分 假文本类，由于存在None值故错分类
				       EI_sar_appcheck_ls1_court_blacklist，EI_sar_appcheck_ls1_financial_blacklist ，
					   EI_sar_appcheck_ls2_financial_blacklist ： boolean 类型 FALSE TURE
					   
					   EI_tongdundata_final_decision    Review  Accept
				   
					   mb_infos level 400多个特征 全部为离散文本类：A,B,C,D,E
					   refInfos level 20 多个特征 全部为离散文本类：A,B,C,D,E
					   
					   tongdundata_policySet_pname 56个  全部为离散文本类 其中有一些特征的数据中可能包含敏感字符
					   
					   
	入模特征6272维  样本量和特征量的比值一般维持在10:1左右，如果样本量过少时，大量的onehot稀疏特征会影响模型效果，不如不要，
	                当样本量比较充分时20:1，可以加入onehot特征试试
	
	观测到的一些调参情况：主要调整参数  learning_rate，max_depth
	    1 当特征维度较高时，树深度越深训练集收敛越快，模型越容易过拟合，表现就是train很快到顶，验证集表现却非常差
		     一般的经验是深度从低到高去调  max_depth：2--10， 但是当样本数量比较大时，这些参数变得不太敏感了
			
		2 learning_rate 一般取值 0.001 当数据量较大时可以先适当扩大步长
		
		3 train_test_split 随机种子：random_state ：None 每一次拆分数据都是随机的，如果指定参数，每一次拆分都是固定的，这样有利于研究其他参数的调优
		
		4 数据集划分，train val test, oot 由于test 和train val可能是同分布的所以，观测的test效果下跌不多，oot上面下跌较多，可能数据分布不同
		  还有一个重要原因就是特征不稳定
		
		5 train val 训练过程中取val最优者，这样的策略存在随机性，模型效果不一定是最好的 
		
		6 特征命名问题，不同数据源开发的特征最好可以在特征命名时加一个标志，比如extend_info特征 前面加EI，
		  这样当我们拿到全量的特征之后就可以很好的控制入模变量，从而评估不同特征的表现
		  
		7 特征不稳定造成过拟合，可以用PSI来判断特征不稳定，造成不稳定的缘故，特征在不同时段的样本命中率不同，这是一个重要原因,
		  训练模型时先统计出不同类型特征的命中率，如果命中率不同，一般选取命中率较高的数据做训练样本可以取得比全量数据更好的效果
		
		8 合并特征时一定要注意将合并后的多出来的索引数据删除，比如unnamed：
		
		9 oot数据的选取，尽量保持与训练集一致，具体的情况就是最新的样本可能是不同模型切流之后作用的结果，
		  故样本分布发生了变化，oot选取尽量和train保持一致
	
	模型训练结果： 样本 (191689, 2826)  oot取3月以后数据大概2w多  EI入模特征大概500维
	    入模特征：EI No tongdunguard，rule , mb_infos, jinpan全量，live_addr
		          oot AUC: 0.642  oot KS: 0.21
		加入jinpan以及addr特征大概有两个点的提升
		
		
社交网络特征开发
   1 网络结构： 度，社区，团伙，环检测
   2 网络节点： 节点特征聚合，包括常见基础年龄，性别住址等，用户排名靠前基特征聚合，用户历史特征聚合
   3 结构与节点：根据亲密度划分不同邻居，然后再进行统计
   
   评估：1 对一度二度节点的用户进行亲密度划分，分为 一度二度分别为 high,middle,low三个等级，分别统计age,sex,history相关的特征
         嘉卡首贷4w样本
         结论：304个特征，无论是否区分亲密度，排名靠前的特征都是二度特征，当引入逾期相关特征最终效果很好，存在特征穿越问题
		 分析： 1 命中率问题， 一度特征
		 SN_one_step_degree rate 0.829325 3.316070298134025
		SN_one_step_high_degree rate 0.46965 1.5913978494623655
		SN_one_step_middle_degree rate 0.54015 2.083958159770434
		SN_one_step_low_degree rate 0.49065 1.7875267502292878
		SN_two_step_degree rate 0.815925 29.47155069399761
		SN_two_step_high_degree rate 0.72015 6.530965771019926
		SN_two_step_middle_degree rate 0.753 16.371281540504647
		SN_two_step_low_degree rate 0.713225 9.836622384240597
		
		一度节点特征命中率0.82左右，符合预期，因为网络中存在一个超级连通子图，其节点占比为82%左右，当用户发生分层之后，命中率下降，各个分层命中率差不多。

        一度节点分层之后其均值低于3，故其统计意义弱化，一度节点的挖掘应该更趋向与涉黑逾期等相关特征。

        二度节点命中率正常，分层之后节点丰富，具有统计意义
		
	第一版：
	一度二度常规统计，
	亲密度分层，
	一度二度触黑名单，
	create_time 时间序列特征
	phone 前缀不纯度，映射地址相关特征：重心，距离
	
	一度二度：idcard_house_price，mobile_use_days，address_house_price，live_to_gz_distance
	
社交网络同步
    1. 2019年新用户征信报告下载共500w左右，将所有征信报告转为标准版统一解析，
	   将获得的网络关系以三元组的形式写下来，最终把所有网络关系合并，统一推入网络中去
		
	2. 在撞表过程中，将通讯录关系中的通讯录名称写下来作为网络节点的一个参考	
	
	
社交网络规则挖掘：
    one_step_degree:分四档
	high fraud risk；14<=X<=20
	middle high fraud risk： 5<=X<14 and  20< x <= 30
	mixed risk : 2<=X<5 
	low risk : X=NaN and X=1 and X >30
	
	one_step_no_approve_size: 分四个等级
	
	

	
紧急联系人社交网络
紧急联系人潜在的关联关系
1. 共用紧急联系人号码，
2 共用紧急联系人姓名
3. 借贷人电话号码做紧急联系人

1 设计方案
    节点：用户id，电话，紧急联系人电话号码，紧急联系人姓名
	关系：拥有手机关系，紧急联系人关系，描述关系
	
	/home/model-test/zhangpeng/Data_Product/DT/Network/
	
2  过程
   1下载拥有紧急联系人关系的用户
   2 通过用户查询其紧急联系人，用户电话节点，将紧急联系人电话节点都当做网络节点写下来
   3 将电话之间存在的关系写下来
	 

3 网络观察情况
  1 40%的分期样本用户存在互用紧急联系人的情况
  2 15%的分期样本只有一个关联用户存在互为紧急联系人关系，这种模式大部分为一个用户的电话为另一个人的紧急联系人
  3 10%的分期样本有两个关联用户，这种模式主要是当前用户和关联用户互为紧急联系人关系，说明这两个人关系密切，
    当然这种关系应该主要关注，两个人互相的关系，姓名是否存在互斥，或者两个人有没有共用同一个紧急联系人电话的情况
	
  4 6%的分期样本有三个个关联用户，这种情况应该是在互为紧急联系人的基础上又多个一个人进来
  
  5 分期坏样本观察总结
    1. 对于同一个紧急联系人描述姓名不同，多个姓名，关系冲突，且此紧急联系人还为借贷人
	   紧急联系人姓名描述有误，使用关系当做名称，比如姓名为朋友
	   
	2. 从关系入手看，推断对同一电话关系描述是否冲突，比如对同一个电话描述为子女和配偶，
	   关注亲密关系，如直系亲属，夫妻关系，再进一步看是否直系亲属同时都借贷
	   
	3. 是否共用一个紧急联系人
	
	4. 将同一电话即做紧急联系人又做电话号码，
	
	5. 个人电话号码个数，紧急联系人个数异常多
	
   6 特征挖掘概览
     个数统计：关联人个数，紧急联系号码个数，个人电话号码个数，姓名描述个数，关系个数
	
         
	
	
					   

	

	 
	 
	
	
	